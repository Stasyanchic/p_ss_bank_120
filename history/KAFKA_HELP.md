# History Microservice Help (Kafka Edition)

## Содержание
- [Описание модуля](#описание-модуля)
- [Функциональные возможности](#функциональные-возможности)
- [Архитектура](#архитектура)
    - [Сущности (Entities)](#сущности-entities)
    - [DTO (Data Transfer Objects)](#dto-data-transfer-objects)
    - [Репозитории (Repositories)](#репозитории-repositories)
    - [Сервисный слой (Services)](#сервисный-слой-services)
    - [Мапперы (Mappers)](#мапперы-mappers)
    - [Обработчики Kafka (Kafka Listeners)](#обработчики-kafka-kafka-listeners)
    - [Конфигурация](#конфигурация)
- [Основные сценарии обработки данных](#основные-сценарии-обработки-данных)
    - [Прием и обработка сообщений аудита](#1-прием-и-обработка-сообщений-аудита)
    - [Запрос истории изменений](#2-запрос-истории-изменений)
- [Технологический стек](#технологический-стек)
- [Обработка ошибок (Exception Handling)](#обработка-ошибок-exception-handling)
- [Безопасность](#безопасность)
- [Логирование и мониторинг](#логирование-и-мониторинг)
- [Развертывание](#развертывание)
- [Дополнительные требования](#дополнительные-требования)

## Описание модуля
History Microservice предназначен для сбора, хранения и агрегации истории изменений из других микросервисов. Он принимает сообщения аудита через Kafka, обрабатывает их и сохраняет в базе данных.

## Функциональные возможности
- Получение событий аудита через Kafka.
- Агрегация данных из всех микросервисов (`account`, `authorization`, `anti_fraud`, `profile`, `transfer`, `public_bank_info`).
- Возможность асинхронного запроса истории изменений через Kafka.
- Интеграция с PostgreSQL.
- JWT-аутентификация.
- Автоматическая генерация документации (Swagger/OpenAPI) для административных задач.

## Архитектура

### Сущности (Entities)
- `History` – хранит технические идентификаторы аудит-записей из всех микросервисов.

### DTO (Data Transfer Objects)
- `HistoryDto` – передача данных истории изменений.

### Репозитории (Repositories)
- `HistoryRepository` – управление данными истории.

### Сервисный слой (Services)
- `HistoryService` – интерфейс для управления историей изменений.
- `HistoryServiceImpl` – реализация логики агрегации и обработки данных.

### Мапперы (Mappers)
- `HistoryMapper` – преобразует сущности истории в DTO и обратно. Использует **MapStruct**.

### Обработчики Kafka (Kafka Listeners)
- `HistoryKafkaListener` – обработчик сообщений Kafka, принимает и сохраняет данные аудита.
- `HistoryKafkaProducer` – отправляет ответы на запросы истории изменений.

### Конфигурация
- `KafkaConfig` – настройка Kafka-коннекторов для приема и отправки сообщений.
- `SwaggerConfig` – настройка Swagger (используется только для внутренних API).

## Основные сценарии обработки данных

### 1. Прием и обработка сообщений аудита
- **Kafka Topic:** `audit.history`
- **Описание:**
    - Источники (другие микросервисы) отправляют сообщения о событиях аудита в Kafka.
    - `HistoryKafkaListener` принимает сообщения и передает их в `HistoryService` для обработки и сохранения в базе.

### 2. Запрос истории изменений
- **Kafka Topic:** `audit.history.request`
- **Описание:**
    - Клиент (другой микросервис) отправляет запрос на получение истории изменений.
    - `HistoryKafkaListener` принимает запрос и передает его в `HistoryService`.
    - Ответ формируется и отправляется через Kafka в топик `audit.history.response`.

## Технологический стек
- Java 17
- Spring Boot 3.x
- Spring Data JPA
- Spring Kafka
- PostgreSQL
- Lombok
- MapStruct
- Spring Security (JWT)
- Swagger/OpenAPI
- Logback (Slf4j)

## Обработка ошибок (Exception Handling)
- `GlobalExceptionHandler` – глобальный обработчик исключений для обработки ошибок Kafka.
- Обрабатывает `EntityNotFoundException`, `ValidationException`, `MessageProcessingException` и другие стандартные ошибки.
- Возвращает структурированные ответы в Kafka-топики ошибок.

## Безопасность
- JWT-аутентификация для административных API.
- Логирование всех событий обработки Kafka-сообщений.

## Логирование и мониторинг
- Используется `Slf4j` для логирования операций.
- Kafka-мониторинг через Prometheus + Grafana.
- Логирование успешных и неуспешных обработок сообщений.

## Развертывание
- Контейнеризация через Docker.
- Kubernetes (Helm Charts).
- Конфигурация через `application.yml`.

## Дополнительные требования
- Код соответствует принципам SOLID.
- Использование **констант или Enum** для предсказуемости данных.
- Предусмотрены unit- и интеграционные тесты для Kafka.
- Готовность к CI/CD (GitLab CI/GitHub Actions).

---

